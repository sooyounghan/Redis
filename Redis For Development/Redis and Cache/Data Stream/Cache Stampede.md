-----
### 캐시 스탬피드 현상
-----
1. 캐시 스탬피드(Cache Stampede) 현상
   - 레디스를 캐시로 활용할 때, 모든 키에 대해 만료 시간을 설정하는 것이 권장
   - 하지만, 대규모 트래픽 환경에서 어떻게 설정하느냐에 따라 캐시 스탬퍼드와 같은 예상치 못한 문제가 발생할 수 있음
<div align="center">
<img src="https://github.com/user-attachments/assets/399772b1-a8fe-4e55-8150-7e5c326d130e">
</div>

   - 애플리케이션 1과 2가 Look Aside 방식으로 레디스를 사용하고 있다고 가정
     + Look Aside 방식에서 애플리케이션은 레디스가 먼저 데이터가 있는지 질의한 후, 데이터가 없을 때 데이터베이스에서 데이터를 읽어오는 과정을 반복
     + 이 때, 레디스에서 특정 키가 만료되는 시점을 생각하면, 만약 여러 개의 애플리케이션에서 바라보던 키가 레디스에서 만료되어 삭제된다면, 이 서버들은 한꺼번에 데이터베이스에 가서 데이터를 읽어오는 과정을 거치는데, 이를 중복 읽기(Duplicate Read)
     + 이후, 각 애플리케이션에서는 읽어온 데이터를 레디스에 쓰게 되는데, 이 또한 여러 번 반복되기 때문에 중복 쓰기(Duplicate Write)가 발생

   - 일반적으로 정렬이나 카운팅처럼 데이터베이스에서 쿼리하는 데 오랜 시간이 걸리는 작업을 미리 계산해서 캐시에 저장해두므로, 캐시에 데이터가 없는 경우 이 데이터를 다시 데이터베이스에 접근해서 계산하는 작업이 필요
   - 레디스에 데이터가 없다는 것을 인지한 여러 애플리케이션에서 동시에 데이터베이스에 접근해 무거운 쿼리를 실행하는 중복 읽기 작용은 데이터베이스에 부하를 줄 수 있으며, 이는 곧 서비스 이슈로 이어질 수 있음
   - 한 번 캐시 스탬피드 현상이 발생하면, 결과적으로 더 많은 데이터가 이 현상의 영향을 받게 되어, 더 큰 문제로 이어질 수 있음 : 이런 이유로 이 현상은 계단식 실패(Cascading Failure)라고 부름

2. 계단식 실패를 줄일 수 있는 여러 방법
   - 적절한 만료 시간 설정 : 캐시 스탬피드를 줄이기 위한 가장 간단한 방법
     + 만료 시간을 너무 짧지 않게 설정하는 것
     + 여러 애플리케이션에서 한꺼번에 접근해야 하는 데이터이며, 반복적으로 사용해야 하는 데이터라면 저장 시점부터 만료 시간을 충분히 길게 설정해주는 것이 좋음

   - 선 계산 : Look Aside 방식으로 캐시를 사용할 때, 애플리케이션은 다음 코드와 비슷하게 동작
     + 캐시에 데이터가 있는지 확인한 뒤, 없으면 데이터베이스에서 데이터를 가져온 뒤 레디스에 저장하는 과정을 거침
<div align="center">
<img src="https://github.com/user-attachments/assets/00d5668c-908f-4403-bb8a-b349af6d7a63">
</div>

   - 캐시 스탬피드가 문제가 되는 이유는 데이터가 만료되는 시점에 여러 애플리케이션에 동시다발적으로 이를 인지하고, 이후 작업을 진행하기 때문임
   - 만약 키가 실제로 만료되기 전 이 값을 미리 갱신해준다면, 여러 애플리케이션에서 한꺼번에 데이터베이스에 접근해 데이터를 읽어오는 과정을 줄여 불필요한 프로세스를 줄일 수 있음
   - 레디스가 실제 만료되기 전 랜덤한 확률로 데이터베이스에 접근해서 데이터를 읽어와 캐시의 값을 갱신하는 과정
<div align="center">
<img src="https://github.com/user-attachments/assets/f99b2291-646f-44f8-aa45-d684d6d2a34c">
</div>

   - hello라는 키의 만료 시간이 10초였을 때, 원래는 10초가 지나야 레디스의 키가 만료되어, 데이터베이스에 접근해서 새로운 데이터를 가지고 와 레디스에 저장했을 것
   - 하지만, 위 함수를 이용하면 랜덤한 확률로 키가 만료되기 전 데이터를 갱신
   - 만약 random()의 값이 6이었을 때, 10 - (6 * 2)는 0보다 작으므로 이 경우 애플리케이션은 데이터베이스에 접근해 데이터를 가지고 온 뒤, 레디스의 값 갱신
   - 단순하게 데이터를 갖고오는 방법보다 더 많은 리소스를 사용한다고 볼 수 있지만, 상황에 따라 캐시 스탬피드 현상을 줄일 수 있으므로 전체적 성능을 향상시키는 방법일 수 있음
   - 이 때, expiry_gap의 값을 적절히 설정해주는 것이 중요하며, 이 값에 따라 불필요한 작업이 늘어나 성능을 줄일 수 있음

3. PER 알고리즘
   - 2015년 캐시 스탬피드 현상을 완화시킬 수 있는 확률적 조기 재계산 알고리즘이 연구
   - PER(Probailistic Early Recomputation) 알고리즘이라 불리며, 이 알고리즘을 이용하면 캐시 값이 만료되기 전 언제 데이터베이스에 접근해서 값을 읽어오면 되는지 최적으로 계싼 가능
   - PER 알고리즘은 다음과 같이 요약 가능
<div align="center">
<img src="https://github.com/user-attachments/assets/74112e9c-7662-4f0a-8e33-450a48f8e275">
</div>

   - timeToCompute * beta * log(rand())는 무작위성을 가진 값 : 이 값은 항목의 만료 여부에 영향을 미침
   - 만약, currnetTime에서 timeToCompute * beta * log((rand))을 빼서 얻은 값이 expiry보다 크다면 조건은 거짓(False)
   - 그러나, 작다면, 조건은 참(True)
   - 즉, 만료 시간이 가까워질수록 currenTime이나 expiry의 차이가 작아지며, rand() 함수가 반환한 무작위 값에 의존하므로 조건이 참이 될 확률이 높아짐
   - 이는 만료 시간이 점점 다가올 때 더 자주 만료된 캐시 항목을 확인하게 되는 것 의미

   - 위의 조건문에서 true를 반환하는 애플리케이션은 데이터를 다시 계산하기 위해 데이터베이스로 이동하게 됨
   - 이 알고리즘은 만료 시간에 가까워질수록 true를 반환할 확률이 증가하므로, 이는 불필요한 재계산을 효과적으로 방지하는 가장 효율적인 방법일 수 있음
   - 따라서, 데이터를 가져오는 과정에서 GET 대신 이 함수를 사용하는 것은 캐시 스탬피드 현상을 줄이고 성능을 최적화하는데 도움
